{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will use the [EuroSAT dataset](https://github.com/phelber/EuroSAT). It consists of 27000 satellite images of different land uses: residential, industrial, highway, river, forest, pasture, herbaceous vegetation, annual crop, permanent crop and sea/lake. For a reference, check the paper below:\n",
    "\n",
    "- Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to import the Eurosat data\n",
    "\n",
    "def load_eurosat_data():\n",
    "    data_dir = 'data/'\n",
    "    x_train = np.load(os.path.join(data_dir, 'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "    x_test  = np.load(os.path.join(data_dir, 'x_test.npy'))\n",
    "    y_test  = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_eurosat_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_new_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function builds a Sequential model. A CNN with 6 layers. The function also compiles the model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(filters = 16, kernel_size = (3,3), input_shape = input_shape, \n",
    "               activation = 'relu', padding = 'SAME', name = 'conv_1'),\n",
    "        Conv2D(filters = 8, kernel_size = (3,3), padding = 'SAME', activation = 'relu', name = 'conv_2'),\n",
    "        MaxPooling2D(pool_size = (8,8), name = 'pool_1'),\n",
    "        Flatten(name = 'flatten'),\n",
    "        Dense(units = 32, activation = 'relu', name = 'dense_1'),\n",
    "        Dense(units = 10, activation = 'softmax', name = 'dense_2')\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# create the model\n",
    "\n",
    "model = get_new_model(x_train[0].shape)\n",
    "print(\"model input shape is \", model.input_shape[1:])\n",
    "print(\"data sample training shape: \", x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to evaluate a model's test accuracy\n",
    "\n",
    "def get_test_accuracy(model, x_test, y_test):\n",
    "    \"\"\"Test model classification accuracy\"\"\"\n",
    "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "    print('accuracy: {acc:0.3f}'.format(acc=test_acc))\n",
    "\n",
    "# Compute the model's initial test accuracy\n",
    "\n",
    "model.summary()\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_checkpoint_every_epoch():\n",
    "    \"\"\"\n",
    "    This function returns a ModelCheckpoint object, saving only weights at every epoch separately.\n",
    "    \"\"\"\n",
    "    checkpoint_path = 'checkpoints_every_epoch/checkpoint_{epoch: 03d}'\n",
    "    checkpoint_every_epoch = ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                            frequency = 'epoch', save_weights_only = True, verbose = 1)\n",
    "    \n",
    "    return  checkpoint_every_epoch\n",
    "\n",
    "\n",
    "\n",
    "def get_checkpoint_best_only():\n",
    "    \"\"\"\n",
    "    This function returns a ModelCheckpoint object, saving only weights if validation accuracy is the best. \n",
    "    \"\"\"\n",
    "    \n",
    "    checkpoint_best_path = 'checkpoints_best_only/checkpoint'\n",
    "    \n",
    "    checkpoint_best_only = ModelCheckpoint(filepath = checkpoint_best_path,\n",
    "                                          save_weights_only = True,\n",
    "                                          monitor = 'val_accuracy', save_best_only = True, verbose = 1)\n",
    "    \n",
    "    \n",
    "    return checkpoint_best_only \n",
    "\n",
    "\n",
    "\n",
    "def get_early_stopping():\n",
    "    \"\"\"\n",
    "    This function returns an EarlyStopping object, monitoring validation accuracy to track \n",
    "    improvements over the last 3 epochs. \n",
    "    \"\"\"\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 3)\n",
    "    \n",
    "    return early_stopping\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the callbacks\n",
    "\n",
    "checkpoint_every_epoch = get_checkpoint_every_epoch()\n",
    "checkpoint_best_only = get_checkpoint_best_only()\n",
    "early_stopping = get_early_stopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.9697 - accuracy: 0.2349\n",
      "Epoch 00001: saving model to checkpoints_every_epoch/ checkpoint_ 01\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33600, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 83s 21ms/sample - loss: 1.9653 - accuracy: 0.2360 - val_loss: 1.6854 - val_accuracy: 0.3360\n",
      "Epoch 2/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.5779 - accuracy: 0.3947\n",
      "Epoch 00002: saving model to checkpoints_every_epoch/ checkpoint_ 02\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.33600 to 0.39800, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 80s 20ms/sample - loss: 1.5773 - accuracy: 0.3943 - val_loss: 1.5099 - val_accuracy: 0.3980\n",
      "Epoch 3/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.4238 - accuracy: 0.4665\n",
      "Epoch 00003: saving model to checkpoints_every_epoch/ checkpoint_ 03\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.39800 to 0.50400, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 80s 20ms/sample - loss: 1.4220 - accuracy: 0.4678 - val_loss: 1.3643 - val_accuracy: 0.5040\n",
      "Epoch 4/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.2975 - accuracy: 0.5161\n",
      "Epoch 00004: saving model to checkpoints_every_epoch/ checkpoint_ 04\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.50400\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.2960 - accuracy: 0.5167 - val_loss: 1.3156 - val_accuracy: 0.4860\n",
      "Epoch 5/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.2237 - accuracy: 0.5481\n",
      "Epoch 00005: saving model to checkpoints_every_epoch/ checkpoint_ 05\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.50400 to 0.52500, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.2238 - accuracy: 0.5470 - val_loss: 1.2708 - val_accuracy: 0.5250\n",
      "Epoch 6/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.1488 - accuracy: 0.5731\n",
      "Epoch 00006: saving model to checkpoints_every_epoch/ checkpoint_ 06\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.52500 to 0.57300, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.1490 - accuracy: 0.5735 - val_loss: 1.1896 - val_accuracy: 0.5730\n",
      "Epoch 7/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.0936 - accuracy: 0.5943\n",
      "Epoch 00007: saving model to checkpoints_every_epoch/ checkpoint_ 07\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.57300 to 0.57500, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.0920 - accuracy: 0.5953 - val_loss: 1.1517 - val_accuracy: 0.5750\n",
      "Epoch 8/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.0616 - accuracy: 0.6099\n",
      "Epoch 00008: saving model to checkpoints_every_epoch/ checkpoint_ 08\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.57500 to 0.60500, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.0603 - accuracy: 0.6108 - val_loss: 1.0776 - val_accuracy: 0.6050\n",
      "Epoch 9/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 1.0207 - accuracy: 0.6240\n",
      "Epoch 00009: saving model to checkpoints_every_epoch/ checkpoint_ 09\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.60500 to 0.60700, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 1.0219 - accuracy: 0.6240 - val_loss: 1.1001 - val_accuracy: 0.6070\n",
      "Epoch 10/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.6497\n",
      "Epoch 00010: saving model to checkpoints_every_epoch/ checkpoint_ 10\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.60700 to 0.63300, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 78s 19ms/sample - loss: 0.9726 - accuracy: 0.6492 - val_loss: 1.0359 - val_accuracy: 0.6330\n",
      "Epoch 11/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.6568\n",
      "Epoch 00011: saving model to checkpoints_every_epoch/ checkpoint_ 11\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.63300\n",
      "4000/4000 [==============================] - 77s 19ms/sample - loss: 0.9278 - accuracy: 0.6565 - val_loss: 1.0177 - val_accuracy: 0.6280\n",
      "Epoch 12/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.9106 - accuracy: 0.6736\n",
      "Epoch 00012: saving model to checkpoints_every_epoch/ checkpoint_ 12\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.63300 to 0.64500, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 78s 19ms/sample - loss: 0.9118 - accuracy: 0.6730 - val_loss: 0.9469 - val_accuracy: 0.6450\n",
      "Epoch 13/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.6890\n",
      "Epoch 00013: saving model to checkpoints_every_epoch/ checkpoint_ 13\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64500\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 0.8571 - accuracy: 0.6883 - val_loss: 1.0829 - val_accuracy: 0.5770\n",
      "Epoch 14/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.8604 - accuracy: 0.6870\n",
      "Epoch 00014: saving model to checkpoints_every_epoch/ checkpoint_ 14\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.64500 to 0.65500, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 78s 19ms/sample - loss: 0.8607 - accuracy: 0.6862 - val_loss: 0.9928 - val_accuracy: 0.6550\n",
      "Epoch 15/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.8329 - accuracy: 0.6925\n",
      "Epoch 00015: saving model to checkpoints_every_epoch/ checkpoint_ 15\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65500\n",
      "4000/4000 [==============================] - 78s 19ms/sample - loss: 0.8316 - accuracy: 0.6930 - val_loss: 0.9885 - val_accuracy: 0.6350\n",
      "Epoch 16/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.8115 - accuracy: 0.6986\n",
      "Epoch 00016: saving model to checkpoints_every_epoch/ checkpoint_ 16\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65500\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 0.8114 - accuracy: 0.6982 - val_loss: 0.9247 - val_accuracy: 0.6460\n",
      "Epoch 17/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.7779 - accuracy: 0.7082\n",
      "Epoch 00017: saving model to checkpoints_every_epoch/ checkpoint_ 17\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.65500 to 0.66200, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 0.7761 - accuracy: 0.7088 - val_loss: 0.8988 - val_accuracy: 0.6620\n",
      "Epoch 18/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.7555 - accuracy: 0.7180\n",
      "Epoch 00018: saving model to checkpoints_every_epoch/ checkpoint_ 18\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.66200 to 0.66800, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 78s 20ms/sample - loss: 0.7565 - accuracy: 0.7178 - val_loss: 0.9098 - val_accuracy: 0.6680\n",
      "Epoch 19/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.7710 - accuracy: 0.7142\n",
      "Epoch 00019: saving model to checkpoints_every_epoch/ checkpoint_ 19\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.66800 to 0.67900, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 77s 19ms/sample - loss: 0.7723 - accuracy: 0.7143 - val_loss: 0.9327 - val_accuracy: 0.6790\n",
      "Epoch 20/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.7387\n",
      "Epoch 00020: saving model to checkpoints_every_epoch/ checkpoint_ 20\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.67900 to 0.69700, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 77s 19ms/sample - loss: 0.7206 - accuracy: 0.7383 - val_loss: 0.8001 - val_accuracy: 0.6970\n",
      "Epoch 21/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.7125 - accuracy: 0.7324\n",
      "Epoch 00021: saving model to checkpoints_every_epoch/ checkpoint_ 21\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.69700 to 0.71000, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 77s 19ms/sample - loss: 0.7167 - accuracy: 0.7312 - val_loss: 0.8000 - val_accuracy: 0.7100\n",
      "Epoch 22/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6991 - accuracy: 0.7442\n",
      "Epoch 00022: saving model to checkpoints_every_epoch/ checkpoint_ 22\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.71000\n",
      "4000/4000 [==============================] - 78s 20ms/sample - loss: 0.6983 - accuracy: 0.7445 - val_loss: 0.8079 - val_accuracy: 0.7090\n",
      "Epoch 23/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6840 - accuracy: 0.7457\n",
      "Epoch 00023: saving model to checkpoints_every_epoch/ checkpoint_ 23\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.71000\n",
      "4000/4000 [==============================] - 78s 19ms/sample - loss: 0.6837 - accuracy: 0.7458 - val_loss: 0.8612 - val_accuracy: 0.6880\n",
      "Epoch 24/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.7581\n",
      "Epoch 00024: saving model to checkpoints_every_epoch/ checkpoint_ 24\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.71000 to 0.72400, saving model to checkpoints_best_only/checkpoint\n",
      "4000/4000 [==============================] - 78s 20ms/sample - loss: 0.6672 - accuracy: 0.7585 - val_loss: 0.7682 - val_accuracy: 0.7240\n",
      "Epoch 25/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6592 - accuracy: 0.7576\n",
      "Epoch 00025: saving model to checkpoints_every_epoch/ checkpoint_ 25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.72400\n",
      "4000/4000 [==============================] - 79s 20ms/sample - loss: 0.6595 - accuracy: 0.7575 - val_loss: 0.8101 - val_accuracy: 0.6970\n",
      "Epoch 26/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6285 - accuracy: 0.7714\n",
      "Epoch 00026: saving model to checkpoints_every_epoch/ checkpoint_ 26\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.72400\n",
      "4000/4000 [==============================] - 77s 19ms/sample - loss: 0.6282 - accuracy: 0.7713 - val_loss: 0.8375 - val_accuracy: 0.6910\n",
      "Epoch 27/50\n",
      "3968/4000 [============================>.] - ETA: 0s - loss: 0.6132 - accuracy: 0.7742\n",
      "Epoch 00027: saving model to checkpoints_every_epoch/ checkpoint_ 27\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.72400\n",
      "4000/4000 [==============================] - 78s 20ms/sample - loss: 0.6141 - accuracy: 0.7742 - val_loss: 0.7899 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f35fc209be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "callbacks = [checkpoint_every_epoch, checkpoint_best_only, early_stopping]\n",
    "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_model_last_epoch(model):\n",
    "    \"\"\"\n",
    "    This function create a new instance of the CNN,\n",
    "    load on the weights from the last training epoch, and return the model.\n",
    "    \"\"\"\n",
    "    input_shape = model.input_shape[1:]\n",
    "    new_model = get_new_model(input_shape)\n",
    "    \n",
    "    checkpoint_path = 'checkpoints_every_epoch/checkpoint_{epoch: 03d}'\n",
    "    checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "    #last_checkpoint = tf.train.last_checkpoint('checkpoints_every_epoch')\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir) \n",
    "    new_model.load_weights(latest)\n",
    "    \n",
    "    return new_model\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_model_best_epoch(model):\n",
    "    \"\"\"\n",
    "    This function creates a new instance of the CNN, load \n",
    "    on the weights leading to the highest validation accuracy, and return the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_shape = model.input_shape[1:]\n",
    "    new_model = get_new_model(input_shape)\n",
    "    \n",
    "    checkpoint_best_path = 'checkpoints_best_only/checkpoint'\n",
    "    \n",
    "    new_model.load_weights(checkpoint_best_path)\n",
    "    \n",
    "    return new_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with last epoch weights:\n",
      "accuracy: 0.716\n",
      "\n",
      "Model with best epoch weights:\n",
      "accuracy: 0.724\n"
     ]
    }
   ],
   "source": [
    "# Load the model weights and verify that the second has a higher validation accuarcy.\n",
    "\n",
    "model_last_epoch = get_model_last_epoch(get_new_model(x_train[0].shape))\n",
    "model_best_epoch = get_model_best_epoch(get_new_model(x_train[0].shape))\n",
    "print('Model with last epoch weights:')\n",
    "get_test_accuracy(model_last_epoch, x_test, y_test)\n",
    "print('')\n",
    "print('Model with best epoch weights:')\n",
    "get_test_accuracy(model_best_epoch, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_eurosatnet():\n",
    "    \"\"\"\n",
    "    This function returns the pretrained EuroSatNet.h5 model.\n",
    "    \"\"\"\n",
    "    new_model = load_model('models/EuroSatNet.h5')\n",
    "    \n",
    "    return new_model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 16, 16, 16)        6416      \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv_8 (Conv2D)              (None, 8, 8, 16)          6416      \n",
      "_________________________________________________________________\n",
      "pool_4 (MaxPooling2D)        (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 41,626\n",
      "Trainable params: 41,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 0.810\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the EuroSatNet model, along with its validation accuracy.\n",
    "\n",
    "model_eurosatnet = get_model_eurosatnet()\n",
    "model_eurosatnet.summary()\n",
    "get_test_accuracy(model_eurosatnet, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "tensor-flow-2-1",
   "graded_item_id": "JaRY0",
   "launcher_item_id": "mJ8fg"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
