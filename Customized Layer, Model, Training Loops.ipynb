{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Customize models, layers, and training loops\n",
    " #### [1. Subclass models](#part_1)\n",
    " #### [2. Customize layers](#part_2)\n",
    " #### [3. Automatic differentiation](#part_3)\n",
    " #### [4. Customize training loops](#part_4)\n",
    " #### [5. Speed up with tf.function decorator](#part_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel_1(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation = 'relu')\n",
    "        self.dense2 = Dense(10)\n",
    "        self.dropout = Dropout(0.4)\n",
    "        \n",
    "    def call(self, inputs, training = True):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation = 'relu')\n",
    "        self.dense2 = Dense(10)\n",
    "        self.dense3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        y1 = self.dense2(inputs)\n",
    "        y2 = self.dense3(y1)\n",
    "        concat = concatenate([x,y2])\n",
    "        return self.softmax(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"part_2\"></a>\n",
    "## Customize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.25537413  0.20966777 -0.15553708]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[ 0.04480226,  0.1271584 , -0.04192461],\n",
      "       [-0.12113389, -0.0102302 , -0.01017084],\n",
      "       [-0.08753927, -0.0038968 ,  0.00480069],\n",
      "       [-0.03051528,  0.01957805, -0.07951196],\n",
      "       [-0.06098795,  0.07705832, -0.02873036]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape =(input_dim, units),\n",
    "                                initializer = 'random_normal')\n",
    "        \n",
    "        self.b = self.add_weight(shape =(units,),\n",
    "                                initializer = 'zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n",
    "x = tf.ones((1,5))\n",
    "\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape =(input_dim, units),\n",
    "                                initializer = 'random_normal',\n",
    "                                trainable = False)\n",
    "        \n",
    "        self.b = self.add_weight(shape =(units,),\n",
    "                                initializer = 'zeros',\n",
    "                                trainable = False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(shape =(input_dim, units),\n",
    "                                initializer = 'random_normal')\n",
    "        \n",
    "        self.b = self.add_weight(shape =(units,),\n",
    "                                initializer = 'zeros')\n",
    "        \n",
    "        self.sum_activation = tf.Variable(initial_value = tf.zeros((units,)),\n",
    "                                     trainable = False)\n",
    "        \n",
    "        self.number_call = tf.Variable(initial_value = 0,\n",
    "                                     trainable = False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis = 0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        \n",
    "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer = MyLayerMean(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06622744 -0.07738343  0.0850624 ]\n",
      "[-0.06622744 -0.07738343  0.0850624 ]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate = self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.02371909 0.00239362 0.01409052 0.00473795 0.01371952 0.01257836\n",
      "  0.01713866 0.00365516 0.09214562 0.02576903 0.01509022 0.0089506\n",
      "  0.0099982  0.00537026 0.01539667 0.00231456 0.01407083 0.01418953\n",
      "  0.07090567 0.00952634 0.01867255 0.01741981 0.01101643 0.00606577\n",
      "  0.05265404 0.04358431 0.04475023 0.03317849 0.00769698 0.0284235\n",
      "  0.002564   0.10037552 0.01181966 0.01361065 0.11349892 0.0041931\n",
      "  0.00572367 0.00883212 0.01180269 0.02055182 0.0135188  0.00949176\n",
      "  0.01203222 0.00430988 0.00531635 0.02313633]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_6 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_2 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_7 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_3 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_8 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"part_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8e04466fd0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.0116837  0.04755135 0.04584097 0.02379757 0.07413681 0.05787175\n",
      " 0.02447213 0.05585188 0.0909888  0.03079492 0.05990052 0.06353568\n",
      " 0.08278518 0.02063971 0.07889149 0.07478199 0.03865117 0.02196957\n",
      " 0.02450367 0.01200093], shape=(20,), dtype=float32)\n",
      "<property object at 0x7f8e5dd1b1d8>\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape = (1,),\n",
    "                                initializer = 'random_normal')\n",
    "        self.b = self.add_weight(shape = (1,),\n",
    "                                initializer = 'zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.m*inputs + self.b\n",
    "    \n",
    "\n",
    "linear_regression = LinearLayer()\n",
    "\n",
    "print(linear_regression(x_train))\n",
    "print(LinearLayer.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 5.8806963\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 0, Loss 5.880696\n",
      "Steps 1, Loss 0.392054\n",
      "Steps 2, Loss 0.033797\n",
      "Steps 3, Loss 0.010370\n",
      "Steps 4, Loss 0.008799\n",
      "Steps 5, Loss 0.008659\n",
      "Steps 6, Loss 0.008616\n",
      "Steps 7, Loss 0.008583\n",
      "Steps 8, Loss 0.008553\n",
      "Steps 9, Loss 0.008527\n",
      "Steps 10, Loss 0.008503\n",
      "Steps 11, Loss 0.008482\n",
      "Steps 12, Loss 0.008463\n",
      "Steps 13, Loss 0.008446\n",
      "Steps 14, Loss 0.008430\n",
      "Steps 15, Loss 0.008417\n",
      "Steps 16, Loss 0.008404\n",
      "Steps 17, Loss 0.008393\n",
      "Steps 18, Loss 0.008383\n",
      "Steps 19, Loss 0.008374\n",
      "Steps 20, Loss 0.008366\n",
      "Steps 21, Loss 0.008359\n",
      "Steps 22, Loss 0.008352\n",
      "Steps 23, Loss 0.008347\n",
      "Steps 24, Loss 0.008341\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "learning_rate = 0.5\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    \n",
    "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    print(\"Steps %d, Loss %f\" % (i, loss.numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[1.0213346]\n",
      "b:2,  trained b:[1.9561117]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8e04384f60>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"part_4\"></a>\n",
    "## Customize training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape =(input_shape[-1], self.units),\n",
    "                                initializer = 'random_normal',\n",
    "                                name = 'kernel')\n",
    "        \n",
    "        self.b = self.add_weight(shape =(self.units,),\n",
    "                                initializer = 'zeros',\n",
    "                                name = 'bias')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate = self.rate)\n",
    "    \n",
    "    \n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00218069 0.01531634 0.01029113 0.02273107 0.00931477 0.02183552\n",
      "  0.11809633 0.02708262 0.00365656 0.02003479 0.01095206 0.01303056\n",
      "  0.02139901 0.00910055 0.00440682 0.00939856 0.01247878 0.00702369\n",
      "  0.04794036 0.06875234 0.01169652 0.03153929 0.01719144 0.00543808\n",
      "  0.010139   0.00969064 0.00261047 0.02261946 0.02031599 0.01082392\n",
      "  0.01004439 0.02356149 0.0166817  0.01292283 0.00243977 0.0967197\n",
      "  0.03258498 0.04366567 0.06559753 0.02098077 0.00902408 0.00216647\n",
      "  0.00656352 0.00634921 0.00411011 0.04950045]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_9 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_4 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_10 (MyLayer)        multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_5 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_11 (MyLayer)        multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_3 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(64,64,46)\n",
    "print(model(tf.ones((1,10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss 3.303, Accuracy 48.408%\n",
      "Epoch 001: Loss 1.906, Accuracy 60.254%\n",
      "Epoch 002: Loss 1.827, Accuracy 65.843%\n",
      "Epoch 003: Loss 1.788, Accuracy 67.546%\n",
      "Epoch 004: Loss 1.758, Accuracy 68.426%\n",
      "Epoch 005: Loss 1.734, Accuracy 69.717%\n",
      "Epoch 006: Loss 1.720, Accuracy 70.474%\n",
      "Epoch 007: Loss 1.716, Accuracy 70.552%\n",
      "Epoch 008: Loss 1.708, Accuracy 70.318%\n",
      "Epoch 009: Loss 1.703, Accuracy 70.741%\n",
      "Duration :235.879\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_dataset:\n",
    "        # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients( zip(grads, model.trainable_variables) )\n",
    "        \n",
    "        #compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        #compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "        \n",
    "    #End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "        \n",
    "    print(\"Epoch {:03d}: Loss {:.3f}, Accuracy {:.3%}\".format(epoch,\n",
    "                                                             epoch_loss_avg.result(),\n",
    "                                                             epoch_accuracy.result()))\n",
    "\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training time here is a bit large. In continue, we will use the `tf.function` decorator to speed up the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.801\n",
      "Test accuracy: 67.142%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: acq\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"part_5\"></a>\n",
    "## Speed up with tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "model = MyModel(64,64,46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator\n",
    "\n",
    "Re-run the above cells after the creation of the model to just before defining the `grad` function. We will see how adding a single line `tf.function` decorator results in the taining speed up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 000: Loss 3.317, Accuracy 47.573%\n",
      "Epoch 001: Loss 1.924, Accuracy 60.733%\n",
      "Epoch 002: Loss 1.837, Accuracy 65.620%\n",
      "Epoch 003: Loss 1.788, Accuracy 68.003%\n",
      "Epoch 004: Loss 1.768, Accuracy 68.960%\n",
      "Epoch 005: Loss 1.747, Accuracy 69.439%\n",
      "Epoch 006: Loss 1.723, Accuracy 69.517%\n",
      "Epoch 007: Loss 1.717, Accuracy 69.717%\n",
      "Epoch 008: Loss 1.724, Accuracy 70.252%\n",
      "Epoch 009: Loss 1.708, Accuracy 70.151%\n",
      "Duration :204.468\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_dataset:\n",
    "        # optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients( zip(grads, model.trainable_variables) )\n",
    "        \n",
    "        #compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        #compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "        \n",
    "    #End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "        \n",
    "    print(\"Epoch {:03d}: Loss {:.3f}, Accuracy {:.3%}\".format(epoch,\n",
    "                                                             epoch_loss_avg.result(),\n",
    "                                                             epoch_accuracy.result()))\n",
    "\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
